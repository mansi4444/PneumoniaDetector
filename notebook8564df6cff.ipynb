{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"STEP_1   ----> importing all the libraries","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:56:40.436083Z","iopub.execute_input":"2022-03-16T17:56:40.436394Z","iopub.status.idle":"2022-03-16T17:56:41.793864Z","shell.execute_reply.started":"2022-03-16T17:56:40.436314Z","shell.execute_reply":"2022-03-16T17:56:41.792961Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPool2D\nfrom keras.layers import Flatten \nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:56:41.795322Z","iopub.execute_input":"2022-03-16T17:56:41.795529Z","iopub.status.idle":"2022-03-16T17:56:47.390179Z","shell.execute_reply.started":"2022-03-16T17:56:41.795502Z","shell.execute_reply":"2022-03-16T17:56:47.388991Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:56:47.398095Z","iopub.execute_input":"2022-03-16T17:56:47.398273Z","iopub.status.idle":"2022-03-16T17:56:47.577934Z","shell.execute_reply.started":"2022-03-16T17:56:47.398251Z","shell.execute_reply":"2022-03-16T17:56:47.576958Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:56:51.228122Z","iopub.execute_input":"2022-03-16T17:56:51.228333Z","iopub.status.idle":"2022-03-16T17:56:51.233107Z","shell.execute_reply.started":"2022-03-16T17:56:51.228311Z","shell.execute_reply":"2022-03-16T17:56:51.231510Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"STEP-2---->Loading the dataset (images in this case) with the help of a helper function that  will help resize it,as well as load images in workspace","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size=250\nlabels = ['PNEUMONIA', 'NORMAL']","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:57:33.275614Z","iopub.execute_input":"2022-03-16T17:57:33.276500Z","iopub.status.idle":"2022-03-16T17:57:33.280087Z","shell.execute_reply.started":"2022-03-16T17:57:33.276437Z","shell.execute_reply":"2022-03-16T17:57:33.279463Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Helper fn\ndef data_loader(data_dir):\n    data = list()\n    for label in labels:\n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (image_size, image_size))\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n                \n    return np.array(data)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:57:33.683753Z","iopub.execute_input":"2022-03-16T17:57:33.684677Z","iopub.status.idle":"2022-03-16T17:57:33.692468Z","shell.execute_reply.started":"2022-03-16T17:57:33.684613Z","shell.execute_reply":"2022-03-16T17:57:33.691696Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = data_loader('../input/chest-xray-pneumonia/chest_xray/chest_xray/train')\ntest = data_loader('../input/chest-xray-pneumonia/chest_xray/chest_xray/test')\nval = data_loader('../input/chest-xray-pneumonia/chest_xray/chest_xray/val')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:58:03.396312Z","iopub.execute_input":"2022-03-16T17:58:03.396642Z","iopub.status.idle":"2022-03-16T17:59:39.431948Z","shell.execute_reply.started":"2022-03-16T17:58:03.396603Z","shell.execute_reply":"2022-03-16T17:59:39.431314Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"print(len(train))\nprint(len(test))\nprint(len(val))","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:59:49.875337Z","iopub.execute_input":"2022-03-16T17:59:49.875551Z","iopub.status.idle":"2022-03-16T17:59:49.881139Z","shell.execute_reply.started":"2022-03-16T17:59:49.875530Z","shell.execute_reply":"2022-03-16T17:59:49.880481Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"SHOWING AN IMAGE USING OpenCV lib ------to visualise ","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:59:50.796786Z","iopub.execute_input":"2022-03-16T17:59:50.796995Z","iopub.status.idle":"2022-03-16T17:59:50.803188Z","shell.execute_reply.started":"2022-03-16T17:59:50.796974Z","shell.execute_reply":"2022-03-16T17:59:50.802090Z"}}},{"cell_type":"code","source":"##showing one ramdom image \nimport cv2 as cv","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:59:58.393562Z","iopub.execute_input":"2022-03-16T17:59:58.393801Z","iopub.status.idle":"2022-03-16T17:59:58.398756Z","shell.execute_reply.started":"2022-03-16T17:59:58.393776Z","shell.execute_reply":"2022-03-16T17:59:58.397743Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"img = cv.imread(\"../input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0115-0001.jpeg\")\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-16T17:59:58.886507Z","iopub.execute_input":"2022-03-16T17:59:58.887137Z","iopub.status.idle":"2022-03-16T17:59:58.943788Z","shell.execute_reply.started":"2022-03-16T17:59:58.887097Z","shell.execute_reply":"2022-03-16T17:59:58.943217Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\nplt.imshow(img)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:00:00.161274Z","iopub.execute_input":"2022-03-16T18:00:00.161569Z","iopub.status.idle":"2022-03-16T18:00:01.132785Z","shell.execute_reply.started":"2022-03-16T18:00:00.161535Z","shell.execute_reply":"2022-03-16T18:00:01.131904Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"STEP-3--->SPLITTING THE DATASET INTO TRAIN AND TEST DATA","metadata":{}},{"cell_type":"code","source":"## dataset splitting\nX_train,y_train = [],[]\nX_test,y_test   = [],[]\nX_val,y_val=[],[]\nfor feature, label in train:\n    X_train.append(feature)\n    y_train.append(label)\nfor feature, label in test:\n    X_test.append(feature)\n    y_test.append(label)\nfor feature, label in val:\n    X_val.append(feature)\n    y_val.append(label)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:00:10.697926Z","iopub.execute_input":"2022-03-16T18:00:10.698222Z","iopub.status.idle":"2022-03-16T18:00:10.713484Z","shell.execute_reply.started":"2022-03-16T18:00:10.698193Z","shell.execute_reply":"2022-03-16T18:00:10.713002Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(np.asarray(X_train).shape)\nprint(np.asarray(X_test).shape)\nprint(np.asarray(y_train).shape)\nprint(np.asarray(y_test).shape)\nprint(np.asarray(X_val).shape)\nprint(np.asarray(y_val).shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:00:11.484841Z","iopub.execute_input":"2022-03-16T18:00:11.485777Z","iopub.status.idle":"2022-03-16T18:00:11.564897Z","shell.execute_reply.started":"2022-03-16T18:00:11.485696Z","shell.execute_reply":"2022-03-16T18:00:11.563814Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"STEP-4---->NORMALIZATION OF IMAGES\nThis step is done to normalize the pixel values of images between 0 and 1.By doing so,we can cut the values that are potential outliers(i.e either too high or too low).\nTo normalize an image,,,,,,img=img/255","metadata":{}},{"cell_type":"code","source":"## data normalization\nX_train = np.array(X_train) / 255\ny_train = np.array(y_train)\nX_test = np.array(X_test) / 255\ny_test = np.array(y_test)\nX_val=np.array(X_val)/255\ny_val=np.array(y_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:01:11.181679Z","iopub.execute_input":"2022-03-16T18:01:11.181960Z","iopub.status.idle":"2022-03-16T18:01:11.952633Z","shell.execute_reply.started":"2022-03-16T18:01:11.181930Z","shell.execute_reply":"2022-03-16T18:01:11.951626Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"type(X_train)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:01:12.139742Z","iopub.execute_input":"2022-03-16T18:01:12.140546Z","iopub.status.idle":"2022-03-16T18:01:12.145904Z","shell.execute_reply.started":"2022-03-16T18:01:12.140507Z","shell.execute_reply":"2022-03-16T18:01:12.145468Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"While reshaping,The numbers mean [batch_size, height, width, channels].                                                             \n-1 means that the length in the dimension is inferred so we don’t have to specify it.                                               \n1 means we’re using a black and white picture so we’ll only have one layer image(i.e. it is grayscale image).","metadata":{}},{"cell_type":"code","source":"X_train = X_train.reshape(-1, image_size, image_size, 1)\ny_train = np.array(y_train)\n\nX_val = X_val.reshape(-1, image_size, image_size, 1)\ny_val = np.array(y_val)\n\nX_test = X_test.reshape(-1, image_size, image_size, 1)\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:01:19.507355Z","iopub.execute_input":"2022-03-16T18:01:19.507579Z","iopub.status.idle":"2022-03-16T18:01:19.512831Z","shell.execute_reply.started":"2022-03-16T18:01:19.507554Z","shell.execute_reply":"2022-03-16T18:01:19.512036Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint(X_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:01:38.829279Z","iopub.execute_input":"2022-03-16T18:01:38.829554Z","iopub.status.idle":"2022-03-16T18:01:38.835263Z","shell.execute_reply.started":"2022-03-16T18:01:38.829521Z","shell.execute_reply":"2022-03-16T18:01:38.834117Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"After converting images to numpy array which is continous data ,we need to convert it to categorical data(0 and 1 specifically),therefore we'll use one hot encoding ..                                                                               \nBy using numeric values, we more easily determine a probability for our values.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n#one-hot encode target column\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:01:56.034424Z","iopub.execute_input":"2022-03-16T18:01:56.034829Z","iopub.status.idle":"2022-03-16T18:01:56.358202Z","shell.execute_reply.started":"2022-03-16T18:01:56.034805Z","shell.execute_reply":"2022-03-16T18:01:56.357092Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"## Model 1 defintion\n\nmodel1 = Sequential()\nmodel1.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu' , input_shape = (250,250,1)))\nmodel1.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\nmodel1.add(Conv2D(16 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid'))\n\nmodel1.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.1))\nmodel1.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid'))\n\nmodel1.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\nmodel1.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\nmodel1.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid'))\n\nmodel1.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\n#model1.add(BatchNormalization())\nmodel1.add(Conv2D(128 , (3,3) , strides = 1 , padding ='valid' , activation = 'relu'))\nmodel1.add(BatchNormalization())\n#model1.add(Dropout(0.1))\nmodel1.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid'))\n\nmodel1.add(Conv2D(256 , (3,3) , strides = 1 , padding ='valid' , activation = 'relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(MaxPool2D((2,2) , strides = 2 , padding ='valid'))\n\nmodel1.add(Conv2D(512 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\n#model1.add(BatchNormalization())\n#model1.add(Conv2D(512 , (3,3) , strides = 1 , padding = 'valid' , activation = 'relu'))\nmodel1.add(BatchNormalization())\n#model1.add(Dropout(0.1))\nmodel1.add(MaxPool2D((2,2) , strides = 2 , padding = 'valid'))\n\nmodel1.add(Flatten())\nmodel1.add(Dense(units = 256 , activation = 'relu'))\nmodel1.add(Dense(units = 64, activation ='relu'))\nmodel1.add(Dropout(0.2))\nmodel1.add(Dense(units = 16, activation ='relu'))\nmodel1.add(Dense(units = 1 , activation = 'sigmoid'))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:02:08.839102Z","iopub.execute_input":"2022-03-16T18:02:08.839419Z","iopub.status.idle":"2022-03-16T18:02:09.152927Z","shell.execute_reply.started":"2022-03-16T18:02:08.839397Z","shell.execute_reply":"2022-03-16T18:02:09.152232Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model1.compile(optimizer = \"rmsprop\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel1.summary()\nprint('\\n')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:02:23.724084Z","iopub.execute_input":"2022-03-16T18:02:23.724863Z","iopub.status.idle":"2022-03-16T18:02:23.746902Z","shell.execute_reply.started":"2022-03-16T18:02:23.724817Z","shell.execute_reply":"2022-03-16T18:02:23.746261Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"The plot_model() function in Keras will create a plot of your network. This function takes a few useful arguments:","metadata":{}},{"cell_type":"code","source":"## plotting model architechture\nfrom keras.utils.vis_utils import plot_model\nplot_model(model1, to_file = 'model_plot.png', show_shapes = True, show_layer_names = True)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:02:50.817357Z","iopub.execute_input":"2022-03-16T18:02:50.817576Z","iopub.status.idle":"2022-03-16T18:02:51.825245Z","shell.execute_reply.started":"2022-03-16T18:02:50.817552Z","shell.execute_reply":"2022-03-16T18:02:51.824557Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"y_predict_cnn = model1.predict(X_test)\ny_predict_cnn\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:10:39.721536Z","iopub.execute_input":"2022-03-16T18:10:39.721745Z","iopub.status.idle":"2022-03-16T18:10:47.787927Z","shell.execute_reply.started":"2022-03-16T18:10:39.721723Z","shell.execute_reply":"2022-03-16T18:10:47.787328Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def convert_to_label(y_predict):\n    ans = []\n    for pair in y_predict:\n        if pair[0]>0.5:\n            ans.append(0)\n        else:\n            ans.append(1)\n    return np.asnumpy(ans)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:11:16.981252Z","iopub.execute_input":"2022-03-16T18:11:16.982090Z","iopub.status.idle":"2022-03-16T18:11:16.988394Z","shell.execute_reply.started":"2022-03-16T18:11:16.982025Z","shell.execute_reply":"2022-03-16T18:11:16.986972Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"y_predict_cnn = convert_to_label(y_predict_cnn)\nprint(len(y_predict_cnn))\nprint(type(y_predict_cnn))\nprint(y_predict_cnn)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:11:31.012132Z","iopub.execute_input":"2022-03-16T18:11:31.012812Z","iopub.status.idle":"2022-03-16T18:11:31.057674Z","shell.execute_reply.started":"2022-03-16T18:11:31.012779Z","shell.execute_reply":"2022-03-16T18:11:31.056490Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"\n\n","metadata":{},"execution_count":null,"outputs":[]}]}